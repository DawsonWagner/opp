---
title: "OPP Veil of Darkness Report"
author: "Samantha Robertson"
date: 12/12/2018
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r load}
suppressMessages(source(here::here("lib", "opp.R")))
suppressMessages(source(here::here("lib", "veil_of_darkness_test.R")))

data.cities <- read_rds(here::here("cache", "aggregated_cities_wsunset_and_subgeo.Rds"))
data.states <- read_rds(here::here("cache", "statewide_wsunset.Rds"))
```

# Abstract
In this report we implement the Veil of Darkness test (Grogger & Ridgeway, 2006) with a city-level dataset containing `r format(nrow(data.cities), big.mark = ",")` traffic stops across seven cities, and with a statewide dataset containing `r format(nrow(data.states), big.mark = ",")`  stops across ten states. The report is intended for readers who are relatively familiar with the test, so the explanation of its details is brief. Using logistic regression, we find statistically significant evidence of discrimination at the nationwide level in both datasets when controlling for the time and location of the stop. City-specific analysis identifies evidence of discrimination in Madison, WI; San Francisco, CA; Nashville, TN; and Philadelphia, PA.

# Introduction
To explore discrimination at the stop level, we implement the Veil of Darkness (VOD) test as proposed by Grogger & Ridgeway (G & R) in 2006. The test uses darkness as a proxy for the visibility of a driver’s race, and assumes that, in the presence of discrimination, a minority driver is more likely than a white driver to be stopped during the day when their race is visible. At night, the driver's race is assumed to be less visible, so the probability that a minority driver is stopped should be closer to the probability that a white driver is stopped.

We begin with a brief summary of the city-level and statewide datasets. This is followed by a description of the methods for data processing, implementation of the test, and analysis of results. Visualizations and regression results are presented first for the city-level data, followed by the statewide data. Finally, we address limitations of the test and potential future directions.

# Summary of the dataset
We consider both city-level stops and statewide highway patrol stops. As in G & R, the analysis is limited to black and white drivers. Throughout the report, the term "minority driver" always refers to black drivers. The requirements of the test are quite stringent: the data must contain date, time and location of the stop, and the race of the driver. An additional control considered is geographic subdivision. Requiring at least 75% non-`NA` values for date, time, driver race, location and geographic subdivision restricts the analysis to to 7 cities[^1]: Arlington, TX; Columbus, OH; Madison, WI; Nashville, TN; New Orleans, LA; Philadelphia, PA; and San Francisco, CA; and 10 states[^2]: Arizona; Connecticut; Michigan; Montana; North Dakota; Ohio; Tennessee; Texas; Wisonsin; and Wyoming.

[^1]: There are 26 cities with at least 75% non-`NA` values for date, time, driver race and stop location. 9 cities (Dallas, El Paso, Green Bay, Camden, Bakersfield, Little Rock, Plano, Hartford and Owensboro) are removed due to data issues, such as duplication, insufficient data in the intertwilight zone, or a negligible number of stops of minority drivers. Another 10 cities (Mesa, San Jose, Aurora, Wichita, Saint Paul, Grand Forks, Oklahoma City, Tulsa, San Antonio and Burlington) are removed because they do not provide one of region, precinct, reporting_area, district, beat, sector or police_grid_number. See Appendix 1 for analysis including the latter 10 cities.

[^2]: Data exploration has not been as rigorously performed on the statewide data. It is possible that some states or years should be removed due to data quality issues or very small percentages of minority drivers. All statewide results should be considered preliminary.

# Methods

## Data Processing
As emphasised by G & R, racial driving patterns may vary significantly with time, so the analysis is limited to the “intertwilight zone”, which is the period of time during which it is light at least one day of the year and dark at least one day of the year. Since the darkness between sunset and dusk is ambiguous, “darkness” is defined as after dusk and “lightness” is defined as before sunset. Thus the intertwilight zone is defined as the minutes between the earliest dusk and the latest sunset. In addition, any stops between sunset and dusk are excluded due to the ambiguity.

A summary of the processed data included in the analysis is provided in Table 1 for the city level data and in Table 2 for the statewide data. Note that the number of stops and percentage of minority drivers are calculated after limiting the data to only stops in the intertwilight zone and only black and white drivers.

```{r data_summary_cities}
col_names <-
  c(
    "City",
    "Total Number of Stops", 
    "Year Range", 
    "Percentage of Minority Drivers"
  )

data.cities %>% 
  group_by(city) %>% 
  summarise(
    n_total = n(),
    min_year = min(year(date)), 
    max_year = max(year(date)),
    year_range = glue::glue("{min_year}-{max_year}"),
    percentage_minority = scales::percent(sum(is_minority_demographic) / n_total)
  ) %>% 
  select(-min_year, -max_year) %>% 
  arrange(desc(n_total)) %>% 
  knitr::kable(col.names = col_names, caption = "Summary of stops in the intertwilight zone (city-level)")
```

```{r data_summary_states}
col_names <-
  c(
    "State",
    "Total Number of Stops", 
    "Year Range", 
    "Percentage of Minority Drivers"
  )

data.states %>% 
  group_by(state) %>% 
  summarise(
    n_total = n(),
    min_year = min(year(date)), 
    max_year = max(year(date)),
    year_range = glue::glue("{min_year}-{max_year}"),
    percentage_minority = scales::percent(sum(is_minority_demographic) / n_total)
  ) %>% 
  select(-min_year, -max_year) %>% 
  arrange(desc(n_total)) %>% 
  knitr::kable(caption = "Summary of stops in the intertwilight zone (statewide)", col.names = col_names)
```


The calculation of sunset and dusk time requires latitude and longitude of the stop and the corresponding timezone. The raw data rarely includes this data, so latitude and longitude are estimated. For the city data, latitude and longitude are estimated using Google Maps, based on the officer’s description of the stop location. This procedure invariably makes a few errors, so any points more than 0.5 degrees in magnitude from the median stop latitude and longitude are considered spurious outliers and are dropped from the dataset. For the statewide data, the county centroid is used[^3].

[^3]: Shapefiles are used from the IPUMS NHGIS American Community Survey, 2016. Source: Steven Manson, Jonathan Schroeder, David Van Riper, and Steven Ruggles. IPUMS National Historical Geographic Information System: Version 13.0 [Database]. Minneapolis: University of Minnesota. 2018. http://doi.org/10.18128/D050.V13.0

We define geographic subdivisions to be used as a control in the regression analyses. For the statewide data, county is the appropriate subdivision, however the most appropriate subdivision varies by city. The subdivision selected for each city, one of precinct, district, beat or sector, is the geographic subdivision variable that has between 5 and 30 distinct values available in the data.

Calculating sunset and dusk times is very slow, so the time of sunset and dusk is calculated only once for each geographic subdivision. For the cities, the sunset and dusk times are calculated at the median latitude and longitude of the stops in the subdivision. For the statewide data, these times are calculated at the county centroid. The intertwilight zone is then defined for each geographic subdivision. This avoids the possibility that stops are included in the analysis at a time and location when and where it is either always light or always dark.

## Analysis

To assess the extent of VOD discrimination, we estimate the change in the proportion of minority drivers stopped from when it is light to when it is dark using both visualizations and logistic regression.

There are a number of factors to consider that may affect the proportion of minority drivers in the at-risk population. Firstly, since driving patterns change over time, we control for clock time in all visualizations and all logistic regression models. As in G & R, we control for clock time in all models with the natural spline of the stop time with six degrees of freedom. To formalize the regression models, let $b$ be the proportion of minority drivers, $d$ be an indicator variable where $d = 1$ if it is dark and $d = 0$ otherwise, and $t$ be the stop time in minutes since midnight. The simplest model is then $d = \beta_0 + \beta_1d + \gamma_1^Tns_6(t)$.

In addition, we fit a second model that additionally controls for and geographic subdivision with an additive categorical variable. Since it is reasonable, if not likely, that discrimination varies greatly by city or state, we also fit this time and geography controlled model on each city individually[^4].

[^4]: There were issues with the state-by-state analysis that only appeared at the very end of the quarter, so it is not included. However, this is certainly something valuable to look at. See Footnote 9 for more details.

A concern raised by G & R is the role of seasonal effects. To control for seasonal effects we fit a third model on the full dataset with an additional additive control that treats the month of the year as a categorical variable. In addition, we fit the time and geography-controlled regression on subsets of the data that includes only the two weeks before and after the two annual Daylight Savings Time (DST) shifts.[^5]

[^5]: The model fit with a month control, and the DST models are only fit on the city-level data, due to time constraints and the large size of the aggregated statewide dataset, however the code is available to fit these models on the statewide data.

The DST shift provides a sharp discontinuity in sunset times that creates a period of one hour that is dark before the shift and light afterwards, or vice versa. The direction of the shift is opposite in the Fall and in the Spring, so we fit separate models for the two shifts. Since the data available to each model is limited to four consecutive weeks of the year, the intertwilight zone is redefined to limit the analysis to stops between the earliest dusk and the latest sunset in these four weeks. This significantly reduces the quantity of data. Table 3 summarizes the data available to the Fall and Spring DST models.

```{r summary_dst_cities}
data.dst_fall <- read_rds(here::here("cache", "vod_dst_fall_data.Rds"))
data.dst_spring <- read_rds(here::here("cache", "vod_dst_spring_data.Rds"))

data.dst_fall %>% 
  count(city, sort = TRUE) %>% 
  rename(n_fall = n) %>% 
  left_join(count(data.dst_spring, city), by = "city") %>% 
  rename(n_spring = n) %>% 
  knitr::kable(
    caption = "Summary of intertwilight zone stops in the Fall and Spring DST periods", 
    col.names = c(
      "City", 
      "Number of stops (Fall)",  
      "Number of stops (Spring)"
    )
  )
```

G & R define the veil of darkness parameter $K_{vod} = \frac{P(B|S, d = 0)P(\bar{B} | S, d = 1)}{P(\bar{B}|S, d = 0)P(B | S, d = 1)}$, where $B$ is the event a driver is black, $S$ is the event a driver is stopped, and $d$ is darkness as we define it, where $d = 1$ indicates it is dark and $d = 0$ indicates it is light. Their analysis focuses on $log K$, which is negative in the presence of discrimination. As described in the paper, $-\beta_1$, where $\beta_1$ is the coefficient on the darkness variable in the logistic regression models, is an estimate for $logK$.  In this analysis we choose to consider the coefficient directly, as we find this a more intuitive and interpretable approach. A negative coefficient estimate $\hat{\beta}_1$ indicates that darkness is associated with a lower proportion of minorities stopped, and thus a negative coefficient is indicative of VOD discrimination.

# Results
## City-level Data

Table 4 gives the percentage of drivers who are black amongst those stopped in the light and in the darkness across all 7 cities. We see in Table 4 that, without controlling for any other variables, the proportion of minority drivers increases in the dark, suggesting the opposite of VOD discrimination.

```{r raw_prop_city}
data.cities %>% 
  group_by(is_dark) %>% 
  summarise(prop_minority = sum(is_minority_demographic) / n(), total = n()) %>% 
  mutate(
    is_dark = if_else(is_dark == TRUE, "Dark", "Light"),
    prop_minority = scales::percent(prop_minority)
  ) %>% 
  knitr::kable(caption = "Percentage of stopped drivers who are black across all citeis, by darkness", col.names = c("", "Percentage Minority Drivers", "Total # Stops"))
```

Figure 1 shows the percentage of stopped drivers who are black in the 90 minutes before and after sunset, controlling for clock time. Both clock time and time relative to sunset is binned by 15 minutes. The proportion is calculated across all cities and one proportion is calculated per combination of clock time and time relative to sunset. The restriction of stops to those between 6:30 PM and 7:30 PM ensures that there are stops in every city in each bin of time relative to sunset and each bin of clock time.

```{r full_city_plot}
plot_prop_minority_by_time(
  data.cities,
  title = "Figure 1",
  subtitle = "The percentage of stopped drivers who are black is lower in the dark,\nwhen controlling for clock time",
  min_clock_time = hms::hms(hours = 18, min = 30), 
  max_clock_time = hms::hms(hours = 19, min = 30),
  smooth_method = "lm"
)
```

Figure 1 suggests that, between 6:30 and 7:30 PM, the proportion of minority drivers in the population of stopped drivers is lower after dark than before dark. The percentage of drivers stopped between 90 and 85 minutes before sunset is between 0.5 and 3 percentage points higher than the percentage of minority drivers amongst those stopped between 90 and 105 minutes after sunset.[^6]

[^6]: It should be noted that if we calculate the proportion of minorities by city (or geographic subdivision) and plot the mean of these proportions for each clock time and time relative to sunset, we produce a plot with very slightly positively sloped lines. This is likely due to the increased influence of smaller cities, which, as we see in Figure 2, tend to show less evidence of discrimination. We felt that Figure 1 is more representative of the effect present in the regressions included in Table 5, as it effectively weights the cities by their size, however, this phenomenon is worth further investigation.

Table 5 shows the estimated coefficient on the darkness indicator variable in the three logistic regression models described above.

```{r full_city_reg}
read_rds(here::here("cache", "vod_full_results.Rds")) %>% 
  knitr::kable(
    caption = "Logistic Regression Estimates (All stops; City data)", 
    col.names = c("Controls", "Coefficient Estimate", "Standard Error")
  )
```

As we would expect from Figure 1, the coefficient on the darkness variable is negative in all three models. The additional controls for geography and month of the year negligibly impact the estimate. All three coefficients are statistically significant at the 0.05 level, suggesting there may be VOD discrimination present. As G & R emphasise, the test provides only a qualitative measure of discrimination.

It is highly possible that discriminatory behavior varies by city. To explore this, we additionally fit the model that controls for clock time and geography on each city individually.  Figure 2 displays the estimated coefficients on the darkness variable with 95% confidence intervals for each city. Nashville, Philadelphia, San Francisco and Madison have negative, statistically significant coefficients, indicating that there is evidence of discrimination at the 0.05 level.

```{r by_city_full}
by_city <- read_rds(here::here("cache", "vod_geo_adj_by_city.Rds"))

by_city %>%  
  mutate(
    low = estimate - 1.96*std.error, 
    high = estimate + 1.96*std.error
  ) %>% 
  ggplot(aes(reorder(city, estimate), estimate)) +
  geom_hline(yintercept = 0, color = "red") +
  geom_point() +
  geom_errorbar(aes(ymin = low, ymax = high)) +
  theme(
    axis.text.x = element_text(hjust = 1, angle = 30)
  ) +
  labs(
    x = NULL,
    y = "Coefficient on Darkness Variable with 95% C.I.",
    title = "Figure 2",
    subtitle = "Clock-time, month and subgeography adjusted models show statistically significant\nVOD discrimination in Madison, San Francisco, Philadelphia and Nashville"
  )
```

Notice that the cities with positive coefficients, Arlington and Columbus, are smaller than cities with negative coefficients like Nashville, Philadelphia and San Francisco.  The largest estimate for the coefficient on the darkness variable is in Madison, WI. Figure 3 replicates Figure 1 using only the data from Madison. The highly downward sloping lines support the evidence for VOD discrimination found in the logistic regression. 

```{r madison_plot}
plot_prop_minority_by_time(
    data.cities,
    city_only = "Madison",
    title = "Figure 3",
    subtitle = "The percentage of stopped drivers in Madison who are black is lower in the dark,\nwhen controlling for clock time",
    min_clock_time = hms::hms(hours = 18, min = 30), 
    max_clock_time = hms::hms(hours = 19, min = 30),
    smooth_method = "lm"
  )
```

### DST Shift
We now limit our analysis to the two weeks either side of the two DST shifts each year. Since the clock time changes by one hour at each shift, there is approximately one hour of the day during these four week periods where it is light in the first two weeks and dark in the second two weeks, or vice versa. To generate Figure 4, we limit the data to stops that occur in the 20 minute period in the middle of this one-hour discontinuity. We aggregate the data over cities and years by day relative to the DST shift. Figure 4 shows the percentage of drivers stopped in this period who are minority drivers.

```{r discontinuity_city}
date_lims <- 
  data.cities %>% 
  filter(is_dst_period == TRUE) %>% 
  summarise(min = min(date), max = max(date))

city_years <- 
  data.cities %>% 
  distinct(city, year = year(date))

city_centroids <-
  data.cities %>% 
  group_by(city) %>% 
  summarise(
    lat = median(lat),
    lng = median(lng),
    tz = min(tz)
  )

dst_sunsets <-
  tibble(
     date = seq(date_lims$min, date_lims$max, by = "days")
  ) %>% 
  mutate(
    is_dst = dst(as.POSIXct(date, tz = Sys.timezone())),
    is_dst_tomorrow = lead(is_dst),
    day_of_change = is_dst == FALSE & is_dst_tomorrow == TRUE | 
      is_dst == TRUE & is_dst_tomorrow == FALSE,
    day_before_change = lead(day_of_change) == TRUE
  ) %>% 
  filter(day_of_change == TRUE | day_before_change == TRUE) %>% 
  mutate(
    year = year(date),
    season = if_else(month(date) < 6, "fall", "spring")
  ) %>% 
  select(year, season, date, day_before_change, day_of_change) %>% 
  left_join(city_years, by = "year") %>% 
  left_join(city_centroids, by = "city") %>% 
  mutate(subgeography = city) %>% 
  left_join(infer_sunset_times(.), by = c("date", "tz", "subgeography"))

dst_times <-
  dst_sunsets %>% 
  mutate(
    day = if_else(day_before_change == TRUE, "day_before", "day_of"),
    sunset_minute = hour(hms(sunset)) * 60 + minute(hms(sunset))
  ) %>% 
  select(-day_before_change, -day_of_change, -date, -sunset, -dusk) %>% 
  spread(key = day, value = sunset_minute) %>% 
  mutate(
    earlier = if_else(day_before < day_of, day_before, day_of),
    later = if_else(day_before > day_of, day_before, day_of),
    min_minute = earlier + 20,
    max_minute = earlier + 40
  ) %>% 
  filter(max_minute < later) %>% 
  select(year, season, city, min_minute)

dst_dates <-
  dst_sunsets %>% 
  filter(day_of_change) %>% 
  distinct(year, season, date) %>% 
  select(year, season, dst_date = date)

full_data <-
  data.cities %>% 
  mutate(
    year = year(date),
    season = if_else(month < 6, "fall", "spring")
  ) %>% 
  left_join(dst_dates, by = c("year", "season")) %>% 
  left_join(dst_times, by = c("year", "season", "city")) %>% 
  mutate(days_since_dst = date - dst_date)

plot_data <-
  full_data %>% 
  filter(
    days_since_dst < days(15),
    days_since_dst > days(-15),
    minute >= min_minute,
    minute <= min_minute + 20
  ) %>% 
  mutate(
    is_dark = factor(is_dark, levels = c(TRUE, FALSE), labels = c("Dark", "Light")),
    season = str_to_title(season),
    before_dst = days_since_dst < 0
  ) %>% 
  group_by(days_since_dst, before_dst, season, is_dark, geo_control) %>% 
  summarise(prop_minority = sum(is_minority_demographic) / n(), n = n()) %>%
  summarise(weighted_mean_prop = weighted.mean(prop_minority, n))
  
plot_data %>% 
  ggplot(aes(days_since_dst, weighted_mean_prop)) +
  geom_vline(xintercept = days(0), color = "grey60") +
  geom_point(aes(color = is_dark)) +
  geom_smooth(method = "lm", color = "grey40", se = FALSE) +
  scale_color_manual(values = c("#2b8cbe", "#feb24c")) +
  labs(
    title = "Figure 4",
    subtitle = "The trend in the proportion of minority drivers stopped in the 20 minute period\nat the center of the DST discontinuity suggests possible VOD discrimination",
    x = "Days since DST change",
    y = "Proportion minority drivers stopped",
    color = NULL
  ) +
  facet_grid(season ~ .)
```

The lines in Figure 4 are sloping slightly downwards in the direction of the days where it is dark at the time of the stops. This suggests there may be VOD discrimination apparent in the data.[^7]

[^7]: See Footnote 6. The same argument applies in this case.

From Figure 4, we expect to see negative coefficient estimates in the logistic regressions. Table 6 shows the regression estimates of the coefficient on the darkness variable with standard errors, for the simple model and the model that adjusts for geographic subdivision. The model that controls for month is not included, since the limitation to the DST period effectively controls for month.

```{r dst_reg_table_city, warning=FALSE}
dst_fall <- read_rds(here::here("cache", "vod_dst_fall.Rds"))
dst_spring <- read_rds(here::here("cache", "vod_dst_spring.Rds"))

tribble(
  ~season, ~adjustments, ~estimate,  ~se, 
  "Fall", "Clock time", coef(dst_fall$model_time_const)[2], coef(summary(dst_fall$model_time_const))[2, 2], 
  "", "Clock time and Geography", coef(dst_fall$model_geo_adjusted)[2], coef(summary(dst_fall$model_geo_adjusted))[2,2],
  "Spring", "Clock time", coef(dst_spring$model_time_const)[2], coef(summary(dst_spring$model_time_const))[2, 2],
  " ", "Clock time and Geography",  coef(dst_spring$model_geo_adjusted)[2], coef(summary(dst_spring$model_geo_adjusted))[2,2]
) %>% 
  column_to_rownames("season") %>% 
  knitr::kable(
    caption = "Logistic Regression Estimates (DST period; City data)",
    col.names = c("Controls", "Coefficient", "Standard Error"), 
    row.names = TRUE
  )
```

The coefficient estimates are all negative, however the estimates from the models that control for both clock time and geography are not statistically significant at the 0.05 level. 

Again, we may be interested in the city-by-city effects. Figure 5 shows the coefficient estimates for the geography adjusted model fit on the DST period data in each city and season with 95% confidence intervals. Though the trends are similar to those seen in the city-by-city analysis of the entire dataset, none of the coefficient estimates are statistically significant at the 0.05 level except for the Fall estimate for Philadelphia.

```{r by_city_dst}
by_city_dst <- 
  read_rds(here::here("cache", "vod_dst_by_city.Rds"))

by_city_dst %>%  
  mutate(
    low = estimate - 1.96*std.error, 
    high = estimate + 1.96*std.error,
    season = str_to_title(season)
  ) %>% 
  ggplot(aes(reorder(city, estimate), estimate)) +
  geom_hline(yintercept = 0, color = "red") +
  geom_point() +
  geom_errorbar(aes(ymin = low, ymax = high)) +
  theme(
    axis.text.x = element_text(hjust = 1, angle = 30)
  ) +
  labs(
    x = NULL,
    y = "Coefficient Estimate with 95% CI",
    title = "Figure 5",
    subtitle = "The clock-time and geography adjusted models fit on the data in the two weeks\neither side of the DST shift do not show statistically significant effects\nat the 0.05 level for any city."
  ) +
  facet_grid(season ~ .)
```

## Statewide Analysis

We now turn our attention to the statewide data. Table 7 displays the raw percentage of stopped drivers who are minority drivers during the light and during the darkness. The percentage differs by less than 0.01 percent, showing no indication of discrimination.

```{r raw_prop_state}
data.states %>% 
  group_by(is_dark) %>% 
  summarise(prop_minority = sum(is_minority_demographic) / n(), total = n()) %>% 
  mutate(
    is_dark = if_else(is_dark == TRUE, "Dark", "Light"),
    prop_minority = scales::percent(prop_minority)
  ) %>% 
  knitr::kable(
    caption = "Proportion of stopped drivers who are black across all states, by darkness", 
    col.names = c("", "Percentage Minority Drivers", "Total # Stops")
  )
```

Figure 6 replicates Figure 1 for the statewide data. We can see that the lines are negatively sloped. Between 6:30PM and 7:30PM, the percentage of drivers amongst those stopped 90-85 minutes before sunset is between 1.5 and 2.5 percentage points higher than the percentage of minority drivers amongst those stopped 90-105 minutes after sunset. From this figure we expect to see evidence of discrimination in the logistic regressions.

```{r statewide_plot}
plot_prop_minority_by_time(
  data.states,
  title = "Figure 6: Statewide Proportion of Minority Drivers By Time",
  subtitle = "The percentage of stopped drivers who are black is lower in the dark,\nwhen controlling for clock time",
  min_clock_time = hms::hms(hours = 18, min = 30), 
  max_clock_time = hms::hms(hours = 19, min = 30),
  smooth_method = "lm"
)
```

The results of the logistic regression models controlling for clock time only and for clock time and geography are shown in Table 8. The coefficient on the darkness variable is negative in both models, and larger in magnitude in the model that controls additionally for geography. Both coefficient estimates are statistically significant at the 0.05 level, suggesting there is VOD discrimination present.[^8]

[^8]: The state-by-state analysis, using the model with county controls, returned exactly the same coefficient and standard error on the darkness variable ($\hat{\beta}_1 = -0.0949$, $SE = 0.00406$) as the aggregated model. I can't find any obvious bugs with the code, which makes me concerned that there is an issue with the way the models are being fit. Since the dataset is so large, I didn't have time to investigate what's going on here before the end of the quarter. The code is in the `run_state_analysis` function in `run_vod.R` (see Appendix 2).

```{r statewide_models}
statewide_models <- 
  list(
    time_only = read_rds(here::here("cache", "vod_statewide_time_const.Rds")),
    time_geo = read_rds(here::here("cache", "vod_statewide_geo_adj.Rds"))
  )

tribble(
  ~controls, ~estimate,                                    ~se,
  "Clock time", statewide_models$time_only$estimate[2], statewide_models$time_only$std.error[2],
  "Clock time and Geography", statewide_models$time_geo$estimate[2], statewide_models$time_geo$std.error[2]
) %>% 
  knitr::kable(
    caption = "Logistic Regression Estimates (All stops; Statewide data)", 
    col.names = c("Controls", "Coefficient Estimate", "Standard Error")
  )
```

# Discussion
With the exception of the clock time and geography adjusted models fit on only the city data in the DST period, we see statistically significant evidence of VOD discrimination across the logistic regression models fit on both the city-level and the statewide data. When we consider discrimination at a city-level, we see statistically significant discrimination in Madison, San Francisco, Philadelphia and Nashville.

The lack of statistical significance in the DST analysis when adjusting for geographic subdivision is likely indicative that the restriction of the data to only four weeks of the year significantly reduces the power of the test. The coefficient estimates in the models fit only on the DST shift data look qualitatively similar to those in the models fit on all of the data, and the model fit on all the data with a control for month showed no significant difference from those that do not control for month. This provides further reason to believe that the discrepancy in statistical significance is a symptom of the significant reduction in the size of the datasets. The quantity of data could be increased by including cities that do not have subdivision data available and running only the clock-time adjusted regression, or adjusting for geography using the city rather than the subdivision.[^9] It will also be interesting to see whether the DST analysis on the much larger statewide dataset has the same issues of power.

[^9]: See 1 for the list of these cities. See Appendix 1 for preliminary results of this analysis.

Despite the high statistical significance observed in many of the models, there are valid concerns with the premise of the veil of darkness test that should be considered. Firstly, the test makes the assumption that darkness is a good proxy for the visibility of a drivers. Further, it assumes that darkness is a binary variable, which implicitly assumes that the "extent" of darkness is the same across all geographic subdivisions at all times after dusk. This ignores factors such as street and ambient lighting which we could justifiably expect to vary significantly between urban, suburban and rural cities and counties.

It also assumes that the visibility of a driver's race is the factor on which discrimination is based. As G & R point out, officers may be using vehicle characteristics to infer a driver's race, a practice called "car profiling", rather than explicitly observing of the driver. In addition, it is feasible that discriminatory behavior varies significantly by officer, which is not accounted for. While our analysis controls for other behaviors that may impact the proportion of minority drivers stopped, like disporportionately patrolling in heavily minority neighborhoods or at times when more minority drivers are driving, through clock time and geographic controls, behaviors like "car profiling" or officer-level effects are not addressed.

# Acknowledgements

My sincere thanks to Sharad for the opportunity to work on this project. It has been a steep but incredibly valuable learning curve. I am so grateful to have worked with such experienced and intelligent people who have been able to teach me how to ask the right questions and demand rigor. I would especially like to thank Amy and Dan for their generous support and patience throughout the quarter. Amy, in particular, has given so much of her time to answer my endless questions and help me through countless bugs, always with such kindness.

# Appendix 1: Preliminary Analysis with 17 Cities

As mentioned in Footnote 1, there are 10 cities that were excluded from the above analysis because they do not include the geographic subdivision of the stops. As we point out above, these cities are theoretically eligible for analysis controlling for geography using the city, rather than the subdivision. In this appendix we provide __very preliminary__ results across the 17 cities. It shoud be recognized that the 10 cities were excluded from the above dataset _before_ exploration of data quality, and thus further exploration should be performed to ensure that these cities should all be included (for example, some cities have very few intertwilight stops).

Table 9 presents the regression estimates for the models that control for clock time, clock time and city, and clock time, city and month, fit on all stops from the 17 cities.

```{r extra_cities_reg}
read_rds(here::here("cache", "vod_no_geo_results.Rds")) %>% 
  mutate(controls = c("Clock time", "Clock time and City", "Clock time, City and Month")) %>% 
  knitr::kable(
    caption = "Logistic Regression Estimates (All stops; 17 Cities)", 
    col.names = c("Controls", "Coefficient Estimate", "Standard Error")
  )
```

Although the coefficient in the model that controls only for clock time is positive and statistically significant, the coefficients in the models that control for city are negative and statistically significant at the 0.05 level. The results when controlling for city match the intuition based on the regression with only 7 cities that controls for subdivision.

```{r, warning=FALSE}
dst_fall <- read_rds(here::here("cache", "vod_dst_no_geo_fall.Rds"))
dst_spring <- read_rds(here::here("cache", "vod_dst_no_geo_spring.Rds"))

tribble(
  ~season, ~adjustments, ~estimate,  ~se, 
  "Fall", "Clock time", coef(dst_fall$model_time_const)[2], coef(summary(dst_fall$model_time_const))[2, 2], 
  "", "Clock time and City", coef(dst_fall$model_geo_adjusted)[2], coef(summary(dst_fall$model_geo_adjusted))[2,2],
  "Spring", "Clock time", coef(dst_spring$model_time_const)[2], coef(summary(dst_spring$model_time_const))[2, 2],
  " ", "Clock time and City",  coef(dst_spring$model_geo_adjusted)[2], coef(summary(dst_spring$model_geo_adjusted))[2,2]
) %>% 
  column_to_rownames("season") %>% 
  knitr::kable(
    caption = "Logistic Regression Estimates (DST period; 17 cities)",
    col.names = c("Controls", "Coefficient", "Standard Error"), 
    row.names = TRUE
  )
```

When limiting the analysis to the DST period only, the clock time and city adjusted models no longer give statistically significant coefficient estimates. The models that adjust only for clock time still give positive, statistically significant coefficients.

# Appendix 2: Code Summary

The bulk of the veil of darkness code is implemented in `opp/lib/vod/veil_of_darkness_test.R`. The function `add_sunset_times` allows the user to filter to the intertwilight zone and save the results. Since adding sunset times is a long process, it's highly recommended to call `add_sunset_times` once, save the result, then use this result in multiple calls to `veil_of_darkness_test`. Set the boolean argument `has_sunset_times` to `TRUE` if you want to run `veil_of_darkness_test` on a pre-processed tibble.

The most important assumption made by `add_sunset_times` is that the data has a column `subgeography`, which is the grouping variable used to calculate timezones and sunset times. The function calculates __one__ timezone per `subgeography`, __one__ sunset time and __one__ dusk time per combination of `subgeography` and `date`, and __one__ intertwilight zone per `subgeography`.

The argument `has_geo_control` to `veil_of_darkness_test` indicates whether or not to run an additional model with an additive control for geographic subdivision. If `has_geo_control = TRUE`, then your data __must__ contain a column `geo_control`, which is used as this control. This allows you to change the variable used as the geographic control by creating a column called `geo_control` (using a `mutate`, `unite`, etc.).

The code to generate the data and results used in this report is contained in `opp/lib/vod/run_vod.R`. __WARNING__: This script takes many days to run if you want to generate all the data and run all the analyses. In particular, the statewide data is huge and the function `run_state_analysis()` will take days. Make sure you comment out the parts of the script you don't want to run.

As a caveat, I generated the data and results included in this report over time and over several smaller scripts, and created the master `run_vod.R` script in retrospect. I have done my best to debug by sight, but since the script takes days, I haven't actually tested `run_vod.R`. I don't guarantee against small bugs.

# Works Cited

Grogger, Jeffrey and Greg Ridgeway, Testing for Racial Profiling in Traffic Stops From Behind a Veil of Darkness. American Statistical Association, 2006. https://www.rand.org/pubs/reprints/RP1253.html